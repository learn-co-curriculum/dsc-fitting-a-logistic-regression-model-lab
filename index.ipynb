{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Logistic Regression Model - Lab\n",
    "\n",
    "## Introduction\n",
    "In the last lecture, you were given a broad overview of logistic regression. This included two separate packages for creating logistic regression models. In this lab, you'll be investigating fitting logistic regressions with statsmodels.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "* Implement logistic regression with statsmodels\n",
    "* Interpret the statistical results associated with regression model parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "The stats model example we covered had four essential parts:\n",
    "* Importing the data\n",
    "* Defining X and y\n",
    "* Fitting the model\n",
    "* Analyzing model results\n",
    "\n",
    "The corresponding code to these four steps was:\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#Step 1: Importing the data\n",
    "salaries = pd.read_csv(\"salaries_final.csv\", index_col = 0)\n",
    "\n",
    "#Step 2: Defining X and y\n",
    "y, X = dmatrices('Target ~ Age  + C(Race) + C(Sex)',\n",
    "                  salaries, return_type = \"dataframe\")\n",
    "\n",
    "#Step 3: Fitting the model\n",
    "logit_model = sm.Logit(y.iloc[:,1], X)\n",
    "result = logit_model.fit()\n",
    "\n",
    "#Step 4: Analyzing model results\n",
    "result.summary()\n",
    "```\n",
    "\n",
    "Most of this should be fairly familiar to you: importing data with pandas, initializing a regression object, and calling the fit method of that object. However, step 2 warrants a slightly more in-depth explanation.\n",
    "\n",
    "The `dmatrices()` method above mirrors the R languages syntax. The first parameter is a string representing the conceptual formula for our model. Afterward, we pass the DataFrame where the data is stored, as well as an optional parameter for the format in which you would like the data returned. The general pattern for defining the formula string is: `y_feature_name ~ x_feature1_name + x_feature2_name + ... + x_featuren_name`. You should also notice that two of the x features, Race and Sex, are wrapped in `C()`. This indicates that these variables are *categorical*, meaning that dummy variables need to be created in order to convert them to numerical quantities. Finally, note that y itself returns a pandas DataFrame with two columns as y itself was originally a categorical variable. With that, it's time to try and define a logistic regression model on your own! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn - Step 1: Import the Data\n",
    "\n",
    "Import the data stored in the file **titanic**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define X and Y\n",
    "\n",
    "For your first foray into logistic regression, you are going to attempt to build a model that classifies whether an individual survived the Titanic shipwreck or not (yes it's a bit morbid). Follow the programming patterns described above to define X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "from patsy import dmatrices\n",
    "\n",
    "y, X = dmatrices('Survived ~ Pclass  + C(Sex) + Age + SibSp +  Fare + C(Embarked)',\n",
    "                  df, return_type = \"dataframe\")\n",
    "#Notes: PassengerId is simply a numerical ordering. No valuable information encoded here\n",
    "#Similarly, Name is not useful for predictions. \n",
    "#P-values below should indicate such if students do include in initial formulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Fit the model\n",
    "\n",
    "Now with everything in place, initialize a regression object and fit your model!\n",
    "\n",
    "### Warning: If you receive an error of the form \"LinAlgError: Singular matrix\"\n",
    "Stats models was unable to fit the model due to some Linear Algebra problems. Specifically, the matrix was not invertible due to not being full rank. In layman's terms, there was a lot of redundant, superfluous data. Try removing some features from the model and running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.444229\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "import statsmodels.api as sm\n",
    "logit_model = sm.Logit(y, X)\n",
    "result = logit_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analyzing results\n",
    "\n",
    "Generate the summary table for your model. Then, comment on the p-values associated with the various features you chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>Survived</td>     <th>  No. Observations:  </th>  <td>   712</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   704</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     7</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 23 Apr 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.3417</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>16:19:07</td>     <th>  Log-Likelihood:    </th> <td> -316.29</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -480.45</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>5.360e-67</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>    5.6378</td> <td>    0.633</td> <td>    8.901</td> <td> 0.000</td> <td>    4.396</td> <td>    6.879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Sex)[T.male]</th>   <td>   -2.6168</td> <td>    0.217</td> <td>  -12.040</td> <td> 0.000</td> <td>   -3.043</td> <td>   -2.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Embarked)[T.Q]</th> <td>   -0.8155</td> <td>    0.598</td> <td>   -1.363</td> <td> 0.173</td> <td>   -1.988</td> <td>    0.357</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Embarked)[T.S]</th> <td>   -0.4036</td> <td>    0.270</td> <td>   -1.494</td> <td> 0.135</td> <td>   -0.933</td> <td>    0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pclass</th>           <td>   -1.2102</td> <td>    0.163</td> <td>   -7.427</td> <td> 0.000</td> <td>   -1.530</td> <td>   -0.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>              <td>   -0.0433</td> <td>    0.008</td> <td>   -5.263</td> <td> 0.000</td> <td>   -0.059</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SibSp</th>            <td>   -0.3796</td> <td>    0.125</td> <td>   -3.043</td> <td> 0.002</td> <td>   -0.624</td> <td>   -0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fare</th>             <td>    0.0012</td> <td>    0.002</td> <td>    0.474</td> <td> 0.635</td> <td>   -0.004</td> <td>    0.006</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               Survived   No. Observations:                  712\n",
       "Model:                          Logit   Df Residuals:                      704\n",
       "Method:                           MLE   Df Model:                            7\n",
       "Date:                Tue, 23 Apr 2019   Pseudo R-squ.:                  0.3417\n",
       "Time:                        16:19:07   Log-Likelihood:                -316.29\n",
       "converged:                       True   LL-Null:                       -480.45\n",
       "                                        LLR p-value:                 5.360e-67\n",
       "====================================================================================\n",
       "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept            5.6378      0.633      8.901      0.000       4.396       6.879\n",
       "C(Sex)[T.male]      -2.6168      0.217    -12.040      0.000      -3.043      -2.191\n",
       "C(Embarked)[T.Q]    -0.8155      0.598     -1.363      0.173      -1.988       0.357\n",
       "C(Embarked)[T.S]    -0.4036      0.270     -1.494      0.135      -0.933       0.126\n",
       "Pclass              -1.2102      0.163     -7.427      0.000      -1.530      -0.891\n",
       "Age                 -0.0433      0.008     -5.263      0.000      -0.059      -0.027\n",
       "SibSp               -0.3796      0.125     -3.043      0.002      -0.624      -0.135\n",
       "Fare                 0.0012      0.002      0.474      0.635      -0.004       0.006\n",
       "====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your analysis here\n",
    "Based on our P-values, most of the current features appear to be significant based on a .05 significance level. That said, the 'Embarked' and 'Fare' features were not significant based on their higher p-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level - up\n",
    "\n",
    "Create a new model, this time only using those features you determined were influential based on your analysis in step 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.445882\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>Survived</td>     <th>  No. Observations:  </th>  <td>   714</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   709</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 23 Apr 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.3399</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>16:19:07</td>     <th>  Log-Likelihood:    </th> <td> -318.36</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -482.26</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.089e-69</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>    5.6008</td> <td>    0.543</td> <td>   10.306</td> <td> 0.000</td> <td>    4.536</td> <td>    6.666</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Sex)[T.male]</th> <td>   -2.6235</td> <td>    0.215</td> <td>  -12.229</td> <td> 0.000</td> <td>   -3.044</td> <td>   -2.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pclass</th>         <td>   -1.3174</td> <td>    0.141</td> <td>   -9.350</td> <td> 0.000</td> <td>   -1.594</td> <td>   -1.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>            <td>   -0.0444</td> <td>    0.008</td> <td>   -5.442</td> <td> 0.000</td> <td>   -0.060</td> <td>   -0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SibSp</th>          <td>   -0.3761</td> <td>    0.121</td> <td>   -3.106</td> <td> 0.002</td> <td>   -0.613</td> <td>   -0.139</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               Survived   No. Observations:                  714\n",
       "Model:                          Logit   Df Residuals:                      709\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Tue, 23 Apr 2019   Pseudo R-squ.:                  0.3399\n",
       "Time:                        16:19:07   Log-Likelihood:                -318.36\n",
       "converged:                       True   LL-Null:                       -482.26\n",
       "                                        LLR p-value:                 1.089e-69\n",
       "==================================================================================\n",
       "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept          5.6008      0.543     10.306      0.000       4.536       6.666\n",
       "C(Sex)[T.male]    -2.6235      0.215    -12.229      0.000      -3.044      -2.203\n",
       "Pclass            -1.3174      0.141     -9.350      0.000      -1.594      -1.041\n",
       "Age               -0.0444      0.008     -5.442      0.000      -0.060      -0.028\n",
       "SibSp             -0.3761      0.121     -3.106      0.002      -0.613      -0.139\n",
       "==================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "y, X = dmatrices('Survived ~ Pclass  + C(Sex) + Age + SibSp ',\n",
    "                  df, return_type = \"dataframe\")\n",
    "\n",
    "logit_model = sm.Logit(y, X)\n",
    "result = logit_model.fit()\n",
    "\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments:\n",
    "\n",
    "Note how removing the insignificant features had little impact on the $R^2$ value of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Well done! In this lab, you practiced using stats models to build a logistic regression model. You then reviewed interpreting the results, building upon your previous stats knowledge, similar to linear regression. Continue on to take a look at building logistic regression models in Sci-kit learn!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
